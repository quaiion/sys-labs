### Задача 1

## Решение

1. Самое очевидное и главное отличие заключается в том, что, в то время как спинлок для блокировки одного из исполнителей использует буквально "крутящийся" кусок кода (очень короткий цикл, как правило), никак не меняющий контекст исполнения у исполнителя, мьютекс передает управление планировщику, который "успыляет" поток и меняет контекст исполнения. Отсюда, соответственно, прикладные отличия. Заблокированный мьютексом поток может висеть часами, планировщик позаботится о том чтобы занять свободный узел (ядро процессора, как правило) чем-то полезным. А вот спинлок грузит узел по полной, никому не отдавая полезный вычилительный ресурс и спуская процессорное время в никуда. Еще одно важное следствие — мьютексы значительно сложнее устроены, а значит являются более высокоуровневым примитивом синхронизации, чем спинлоки. Строго говоря, мьютексы могут непосредственно использовать спинлоки в рамках конкретной реализации. В силу приведенных причин спинлоки принято использовать в низкоуровневом, системном софте, где сложная структура мьютексов либо нереализуема вообще, либо дает оверхед больший, чем ожидаемые сравнительные потери от использования спинлоков. Последнее, однако, иногда оказывается верно и для довольно высокоуровневого софта — главное здраво оценивать длительность блокировок, в которых будут висеть вычислительные узлы.

2. Допустим, под ОЧЕНЬ активным использованием понимается очень часто повторяющийся вход в одну и ту же критическую секцию по меньшей мере одним из исполнителей — например, когда критическая секция вложена в маленький цикл и представляет из себя пару простых строчек кода. Проблема тут вероятно заключается в том, что частота исполнения критической секции может "срезонировать" с частотой опроса состояния спинлоком и вызвать непозволительно долгую (по крайней мере для спинлока) блокировку одного из исполнителей. Вот пример: критическая секция маленькая и погружена в цикл, включающий только ее. Ядру 2 не повезло упереться в начало критической секции, когда она была занята ядром 1. Ядро 2 встает в спинлок и (в рамках сниппета, приведенного в задании) отправляется исполнять `arch_spin_relax();` в первой итерации. Допустим, исполнение этой функции вместе с проверкой условия while'а, на котором крутится спинлок, занимает условное время t. Пусть у ядра 1 уходит примерно такое же время t на то, чтобы пролететь насквозь критическую секцию, закрыть ее и открыть снова на новой итерации цикла, оборачивающего критическую секцию + проверить один раз условие цикла спинлока (это не противоречит логике, потому что исполнение `arch_spin_relax();` в указанный список дел не входит). Тогда ядро 1 успеет отобрать контроль над критической секцией мгновенно, не отдавая его ядру 2. А поскольку исполнять `arch_spin_relax();` в этом случае не придется, ядро 1 снова прилетит в точку перехвата управления критической секцией через t. Таким образом раз в t ядро 1 будет сохранять контроль над критической секцией, а ядро 2 будет продолжать блокироваться — и продолжаться это может до бесконечности (точнее, пока ядру 1 есть что считать во внешнем цикле). Это приводит к большим проблемам распараллеливания даже при адекватной балансировке нагрузки.

3. Есть еще проблема того, что при такой простой реализации критических секций, если в какой-то момент окажутся заблокированными сразу несколько потоков, то то, какой из них первым получит контроль над критической секцией, определяется почти случайно. Это может привести к аналогичной проблеме "простаивания" одного из исполнителей, но почему-то хочется верить, что в общем случае теории вероятностей оказывается достаточно, чтобы эффект был малозначительным.

3. Я очень хотел бы проверить свои гипотезы, но Zephyr не собрался...

4. Худший эффект описанных недостатков — это простаивание отдельных ядер на спинлоках неограниченно долгое время. Во-первых, разделяемые кэши слишком сильно подстроятся под нагрзуку одного из ядер, во-вторых, (пальцем в небо) самим ядрам может стать не очень хорошо от обработки пачки из условно 8 инструкций в течение нескольких часов, в-третьих, как уже было замечено, сильно падает степень распараллеливания вычислений, т.к. из-за простаиваний часть нагрузки выполняется последовательно. Подозреваю, что из перечисленных проблем только вторая может возникнуть на физическом железе и не может возникнуть при запуске на Qemu.

5. Проблема из пункта 2 наиболее экономно исправляется переменной, позволяющий отслеживать перехват управления одним и тем же исполнителем несколько раз подряд, и небольшим штрафом к времени исполнения критической секции для таких исполнителей. Если я правильно прочитал документацию, лишний вызов `arch_spin_relax()` в качестве штрафа проблем создать не должен. При некоторых типах нагрузки это слегка замедлит исполнение на штрафуемом ядре, зато исключит возможность описанного выше сценария. Вот пример на сниппете из задания:

```c
node_id_t node;

struct k_spinlock {
        atomic_t locked;
        node_id_t used_by;
}

static ALWAYS_INLINE k_spinlock_key_t k_spin_lock(struct k_spinlock *l) {
        arch_irq_lock();

        while (!atomic_cas(&l->locked, 0, 1)) {
                arch_spin_relax();
        }

        if (&l->used_by == node) {
                arch_spin_relax();
        } else {
                &l->used_by = node;
        }
}

static ALWAYS_INLINE void k_spin_unlock(struct k_spinlock *l,
                                        k_spinlock_key_t key) {
        (void)atomic_clear(&l->locked);

        arch_irq_unlock(key.key);
}
```

6. Проблема из пункта 3 решается вводом очередей заблокированных исполнителей. Я постарался написать как можно более экономную очередь на односвязном списке, но, боюсь, оверхед от использования этого монстра перевешивает преимущества (если они вообще есть):

```c
#define N_NODES // <???>
#define FREE_NODE N_NODES

node_id_t node; // supposed to be a simple integer greater than 0

struct k_spinlock {
        atomic_t locked;
        node_id_t head_node;
        node_id_t tail_node;
        node_id_t node_list[N_NODES + 1];
}

void k_spinlock_init(struct k_spinlock_t *l) {
        l->head_node = FREE_NODE;
        l->tail_node = FREE_NODE;
}

static ALWAYS_INLINE k_spinlock_key_t k_spin_lock(struct k_spinlock *l) {
        arch_irq_lock();

        any_other_critical_section_lock();
        (l->node_list)[l->tail_node] = node;
        l->tail_node = node;
        (l->node_list)[node] = FREE_NODE;
        any_other_critical_section_unlock();

        while (!atomic_cas(&l->locked, 0, 1) ||
               !(l->head_node == node || l->head_node == FREE_NODE)) {
                arch_spin_relax();
        }

        l->head_node = (l->node_list)[node];
        if (l->head_node == FREE_NODE) {
                l->tail_node = FREE_NODE;
        }
}

static ALWAYS_INLINE void k_spin_unlock(struct k_spinlock *l,
                                        k_spinlock_key_t key) {
        (void)atomic_clear(&l->locked);

        arch_irq_unlock(key.key);
}
```

*И все же мне почему-то кажется, что теории вероятностей должно быть достаточно...*
